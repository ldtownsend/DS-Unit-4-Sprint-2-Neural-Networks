{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "    - The basic component of a neural net. It is where an input (initial input, or from the prior layer) and weight are multiplied. Said differently, it is an element in each layer's calculation of the activation function.\n",
    "- **Input Layer:** \n",
    "    - As the name would suggest, they are the inputs... It is the first layer of 'net. There is no function or computation being performed in the input layer. From lecture: \"Typically node maps are drawn with one input node for each of the different inputs/features/columns of our dataset, that will be passed into the network.\"\n",
    "\n",
    "- **Hidden Layer:**\n",
    "    - The layers which are performing intermediate computations. We don't directly interact with them. \n",
    "- **Output Layer:**\n",
    "    - This is the final layer of the neural net. This is where we access some output vector. The equivalent of a y_pred from earlier units.\n",
    "- **Activation:**\n",
    "    - It's the function that occurs at each node in the network. It forces the value of the node down to a (typically if not always(..?) 0.0 through 1.0 value which determines whether or not the node is activated or not. From lecture, \"... they are sometimes referred to as transfer functions because they determine how much signal is transferred to the next layer.\"\n",
    "- **Backpropagation:**\n",
    "    - It is the backward propagation of errors. It is the method by which weights are reversed and updated in each epoch of the neural net.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. You will not be able to achieve more than ~50% with the simple perceptron. Explain why you could not achieve a higher accuracy with the *simple perceptron* architecture, because it's possible to achieve ~95% accuracy on this dataset. Provide your answer in markdown (and *optional* data anlysis code) after your perceptron implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values\n",
    "y = np.reshape(y,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 2 * np.random.random((2,1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3278272 ],\n",
       "       [0.33390702],\n",
       "       [0.3278272 ],\n",
       "       ...,\n",
       "       [0.3278272 ],\n",
       "       [0.3278272 ],\n",
       "       [0.33390702]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum = np.dot(X, weights)\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[-329.51210898]\n",
      " [-329.07424731]]\n",
      "Output after training\n",
      "[[0.790481  ]\n",
      " [0.79148617]\n",
      " [0.790481  ]\n",
      " ...\n",
      " [0.790481  ]\n",
      " [0.790481  ]\n",
      " [0.79148617]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1):\n",
    "    \n",
    "    # Weighted sum of inputs / weights\n",
    "    weighted_sum = np.dot(X, weights) + bias\n",
    "    \n",
    "    # Activate!\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Cac error\n",
    "    error = y - activated_output\n",
    "#     print(y.shape), print(activated_output.shape)\n",
    "    adjustments = error * sigmoid_derivative(activated_output)\n",
    "#     print(error.shape), print(activated_output.shape)\n",
    "#     print(adjustments.shape)\n",
    "#     Update the Weights\n",
    "    weights += np.dot(X.T, adjustments)\n",
    "    \n",
    "    bias += error\n",
    "        \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"Output after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = 2\n",
    "        self.hiddenNodes = 3\n",
    "        self.outputNodes = 1\n",
    "\n",
    "        # Initial Weights\n",
    "        # 2x3 Matrix Array for the First Layer\n",
    "        self.weights1 = np.random.rand(self.inputs, self.hiddenNodes) + 1\n",
    "       \n",
    "        # 3x1 Matrix Array for Hidden to Output\n",
    "        self.weights2 = np.random.rand(self.hiddenNodes, self.outputNodes) + 1\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        aka \"predict\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs => hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        # Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "        \n",
    "    def backward(self, X,y,o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        \n",
    "        # Error in Output\n",
    "        self.o_error = y - o\n",
    "        \n",
    "        # Apply Derivative of Sigmoid to error\n",
    "        # How far off are we in relation to the Sigmoid f(x) of the output\n",
    "        # ^- aka hidden => output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
    "        \n",
    "        # z2 error\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        \n",
    "        # How much of that \"far off\" can explained by the input => hidden\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        # Adjustment to first set of weights (input => hidden)\n",
    "        self.weights1 += X.T.dot(self.z2_delta)\n",
    "        # Adjustment to second set of weights (hidden => output)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "        \n",
    "\n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X,y,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[0.96266602]\n",
      " [0.9700926 ]\n",
      " [0.96266602]\n",
      " ...\n",
      " [0.96266602]\n",
      " [0.96266602]\n",
      " [0.9700926 ]]\n",
      "Loss: \n",
      " 0.4382484594047015\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 2000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 3000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 4000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 5000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 6000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 7000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 8000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 9000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 10000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[3.14274699e-51]\n",
      " [1.77336445e-58]\n",
      " [3.14274699e-51]\n",
      " ...\n",
      " [3.14274699e-51]\n",
      " [3.14274699e-51]\n",
      " [1.77336445e-58]]\n",
      "Loss: \n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "# Train my 'net\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "# Number of Epochs / Iterations\n",
    "for i in range(10000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
    "    nn.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "264   54    1   0       110   206    0        0      108      1      0.0   \n",
       "60    71    0   2       110   265    1        0      130      0      0.0   \n",
       "140   51    0   2       120   295    0        0      157      0      0.6   \n",
       "28    65    0   2       140   417    1        0      157      0      0.8   \n",
       "136   60    0   2       120   178    1        1       96      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "264      1   1     2       0  \n",
       "60       2   1     2       1  \n",
       "140      2   0     2       1  \n",
       "28       2   1     2       1  \n",
       "136      2   0     2       1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(df)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "264   54    1   0       110   206    0        0      108      1      0.0   \n",
       "60    71    0   2       110   265    1        0      130      0      0.0   \n",
       "140   51    0   2       120   295    0        0      157      0      0.6   \n",
       "28    65    0   2       140   417    1        0      157      0      0.8   \n",
       "136   60    0   2       120   178    1        1       96      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "264      1   1     2       0  \n",
       "60       2   1     2       1  \n",
       "140      2   0     2       1  \n",
       "28       2   1     2       1  \n",
       "136      2   0     2       1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = df[feats].values\n",
    "X_2 = X_2 / np.amax(X_2, axis=0)\n",
    "y_2 = df['target'].values\n",
    "y_2 = np.reshape(y_2,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "Epoch 1/5\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 5.7696 - accuracy: 0.4356\n",
      "Epoch 2/5\n",
      "303/303 [==============================] - 0s 77us/sample - loss: 5.4469 - accuracy: 0.4290\n",
      "Epoch 3/5\n",
      "303/303 [==============================] - 0s 72us/sample - loss: 5.1882 - accuracy: 0.4224\n",
      "Epoch 4/5\n",
      "303/303 [==============================] - 0s 65us/sample - loss: 4.9259 - accuracy: 0.4191\n",
      "Epoch 5/5\n",
      "303/303 [==============================] - 0s 68us/sample - loss: 4.7018 - accuracy: 0.4125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb3502feef0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=13, activation='relu'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_2,y_2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model has an accuracy below 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7060 - accuracy: 0.4109\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 148us/sample - loss: 0.6809 - accuracy: 0.6089\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.6585 - accuracy: 0.6832\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.6363 - accuracy: 0.7178\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.6159 - accuracy: 0.7228\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.5960 - accuracy: 0.7723\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.5774 - accuracy: 0.8020\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.5602 - accuracy: 0.7871\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.5454 - accuracy: 0.7723\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 145us/sample - loss: 0.5310 - accuracy: 0.7970\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.5185 - accuracy: 0.8020\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.5065 - accuracy: 0.8119\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.4968 - accuracy: 0.7921\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.4873 - accuracy: 0.8020\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.4761 - accuracy: 0.8168\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4694 - accuracy: 0.8168\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.4615 - accuracy: 0.8119\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.4539 - accuracy: 0.8267\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.4476 - accuracy: 0.8317\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.4442 - accuracy: 0.8069\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.2330 - accuracy: 0.8515\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7278 - accuracy: 0.5149\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 189us/sample - loss: 0.6877 - accuracy: 0.5248\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.6523 - accuracy: 0.5990\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.6223 - accuracy: 0.7475\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.5945 - accuracy: 0.7871\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.5717 - accuracy: 0.7822\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.5493 - accuracy: 0.7822\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.5292 - accuracy: 0.7871\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.5081 - accuracy: 0.8020\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.4936 - accuracy: 0.7921\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.4774 - accuracy: 0.7921\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 153us/sample - loss: 0.4628 - accuracy: 0.8168\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.4557 - accuracy: 0.8069\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.4428 - accuracy: 0.7970\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4356 - accuracy: 0.7970\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4275 - accuracy: 0.8020\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.4205 - accuracy: 0.7970\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 145us/sample - loss: 0.4151 - accuracy: 0.8020\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.4104 - accuracy: 0.8069\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.4052 - accuracy: 0.8020\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3917 - accuracy: 0.7723\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7377 - accuracy: 0.3218\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.6985 - accuracy: 0.5149\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 153us/sample - loss: 0.6700 - accuracy: 0.6089\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 152us/sample - loss: 0.6435 - accuracy: 0.6733\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.6182 - accuracy: 0.7178\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.5958 - accuracy: 0.7723\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.5737 - accuracy: 0.8020\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.5546 - accuracy: 0.8020\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.5340 - accuracy: 0.8119\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.5150 - accuracy: 0.8218\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.4984 - accuracy: 0.8267\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.4824 - accuracy: 0.8465\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4664 - accuracy: 0.8465\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.4512 - accuracy: 0.8465\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.4456 - accuracy: 0.8515\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.4254 - accuracy: 0.8564\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 153us/sample - loss: 0.4210 - accuracy: 0.8564\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.4096 - accuracy: 0.8564\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.4032 - accuracy: 0.8762\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.3989 - accuracy: 0.8515\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.4512 - accuracy: 0.7723\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6781 - accuracy: 0.6188\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.6559 - accuracy: 0.6634\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.6411 - accuracy: 0.7030\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.6272 - accuracy: 0.6980\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.6148 - accuracy: 0.7178\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 97us/sample - loss: 0.6013 - accuracy: 0.7376\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 101us/sample - loss: 0.5904 - accuracy: 0.7525\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.5798 - accuracy: 0.7574\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 91us/sample - loss: 0.5693 - accuracy: 0.7723\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 91us/sample - loss: 0.5598 - accuracy: 0.7772\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.5506 - accuracy: 0.7772\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.5409 - accuracy: 0.7772\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.5311 - accuracy: 0.7822\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 93us/sample - loss: 0.5239 - accuracy: 0.7772\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 97us/sample - loss: 0.5172 - accuracy: 0.7772\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 97us/sample - loss: 0.5107 - accuracy: 0.7822\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.5028 - accuracy: 0.7822\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.4962 - accuracy: 0.8020\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.4905 - accuracy: 0.8069\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 91us/sample - loss: 0.4843 - accuracy: 0.7970\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.2952 - accuracy: 0.8416\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6643 - accuracy: 0.5842\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.6343 - accuracy: 0.7079\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 96us/sample - loss: 0.6136 - accuracy: 0.7574\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 106us/sample - loss: 0.5948 - accuracy: 0.7574\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 96us/sample - loss: 0.5743 - accuracy: 0.7822\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 96us/sample - loss: 0.5536 - accuracy: 0.8020\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 117us/sample - loss: 0.5357 - accuracy: 0.7921\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 109us/sample - loss: 0.5204 - accuracy: 0.7970\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 103us/sample - loss: 0.5081 - accuracy: 0.8020\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 96us/sample - loss: 0.4968 - accuracy: 0.7970\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 103us/sample - loss: 0.4852 - accuracy: 0.7970\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 104us/sample - loss: 0.4753 - accuracy: 0.7970\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 102us/sample - loss: 0.4671 - accuracy: 0.8020\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 132us/sample - loss: 0.4586 - accuracy: 0.8069\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.4533 - accuracy: 0.8020\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 107us/sample - loss: 0.4461 - accuracy: 0.8069\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 105us/sample - loss: 0.4405 - accuracy: 0.8069\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.4343 - accuracy: 0.7970\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 88us/sample - loss: 0.4299 - accuracy: 0.8168\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.4270 - accuracy: 0.8119\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 947us/sample - loss: 0.3734 - accuracy: 0.7921\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6970 - accuracy: 0.5545\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.6794 - accuracy: 0.5792\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.6641 - accuracy: 0.5941\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.6487 - accuracy: 0.6980\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.6341 - accuracy: 0.7327\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.6211 - accuracy: 0.7525\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 100us/sample - loss: 0.6081 - accuracy: 0.7574\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 98us/sample - loss: 0.5937 - accuracy: 0.7673\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.5814 - accuracy: 0.7921\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.5679 - accuracy: 0.8069\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.5563 - accuracy: 0.8218\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 104us/sample - loss: 0.5433 - accuracy: 0.8267\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 101us/sample - loss: 0.5300 - accuracy: 0.8218\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 110us/sample - loss: 0.5173 - accuracy: 0.8416\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 114us/sample - loss: 0.5037 - accuracy: 0.8416\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 409us/sample - loss: 0.4933 - accuracy: 0.8366\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.4814 - accuracy: 0.8366\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 100us/sample - loss: 0.4721 - accuracy: 0.8515\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 106us/sample - loss: 0.4631 - accuracy: 0.8515\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 110us/sample - loss: 0.4550 - accuracy: 0.8465\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 995us/sample - loss: 0.4779 - accuracy: 0.7426\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7033 - accuracy: 0.4059\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 53us/sample - loss: 0.6898 - accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 56us/sample - loss: 0.6767 - accuracy: 0.6040\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 52us/sample - loss: 0.6663 - accuracy: 0.6584\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 55us/sample - loss: 0.6561 - accuracy: 0.6782\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 54us/sample - loss: 0.6475 - accuracy: 0.6782\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 53us/sample - loss: 0.6413 - accuracy: 0.6832\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 55us/sample - loss: 0.6357 - accuracy: 0.6782\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 52us/sample - loss: 0.6299 - accuracy: 0.6782\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 55us/sample - loss: 0.6239 - accuracy: 0.6881\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 56us/sample - loss: 0.6182 - accuracy: 0.6881\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 52us/sample - loss: 0.6126 - accuracy: 0.6980\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 56us/sample - loss: 0.6077 - accuracy: 0.7030\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 51us/sample - loss: 0.6028 - accuracy: 0.7030\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 51us/sample - loss: 0.5975 - accuracy: 0.7030\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 61us/sample - loss: 0.5925 - accuracy: 0.7129\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 57us/sample - loss: 0.5889 - accuracy: 0.7277\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 63us/sample - loss: 0.5845 - accuracy: 0.7475\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 56us/sample - loss: 0.5796 - accuracy: 0.7376\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 59us/sample - loss: 0.5752 - accuracy: 0.7376\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 917us/sample - loss: 0.5353 - accuracy: 0.8614\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7462 - accuracy: 0.5050\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 67us/sample - loss: 0.7235 - accuracy: 0.5099\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 63us/sample - loss: 0.7063 - accuracy: 0.5248\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6968 - accuracy: 0.4851\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 67us/sample - loss: 0.6861 - accuracy: 0.5050\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 63us/sample - loss: 0.6765 - accuracy: 0.5495\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 53us/sample - loss: 0.6669 - accuracy: 0.5792\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.6576 - accuracy: 0.6089\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 59us/sample - loss: 0.6494 - accuracy: 0.6337\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 67us/sample - loss: 0.6398 - accuracy: 0.6683\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 60us/sample - loss: 0.6295 - accuracy: 0.7030\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 68us/sample - loss: 0.6201 - accuracy: 0.7178\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 74us/sample - loss: 0.6098 - accuracy: 0.7327\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6004 - accuracy: 0.7277\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 66us/sample - loss: 0.5923 - accuracy: 0.7475\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 70us/sample - loss: 0.5844 - accuracy: 0.7624\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 63us/sample - loss: 0.5769 - accuracy: 0.7723\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 70us/sample - loss: 0.5687 - accuracy: 0.7723\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 66us/sample - loss: 0.5616 - accuracy: 0.7822\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 62us/sample - loss: 0.5555 - accuracy: 0.7921\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.5381 - accuracy: 0.7921\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6726 - accuracy: 0.5693\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 71us/sample - loss: 0.6561 - accuracy: 0.6238\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6407 - accuracy: 0.6386\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 62us/sample - loss: 0.6259 - accuracy: 0.6832\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 61us/sample - loss: 0.6101 - accuracy: 0.7822\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 61us/sample - loss: 0.5976 - accuracy: 0.8069\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 60us/sample - loss: 0.5869 - accuracy: 0.8119\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 62us/sample - loss: 0.5789 - accuracy: 0.7970\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.5693 - accuracy: 0.8020\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 60us/sample - loss: 0.5614 - accuracy: 0.7822\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 59us/sample - loss: 0.5527 - accuracy: 0.7772\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 60us/sample - loss: 0.5443 - accuracy: 0.7871\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 58us/sample - loss: 0.5334 - accuracy: 0.8168\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 65us/sample - loss: 0.5231 - accuracy: 0.8366\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 57us/sample - loss: 0.5136 - accuracy: 0.8416\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 60us/sample - loss: 0.5062 - accuracy: 0.8416\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 60us/sample - loss: 0.4997 - accuracy: 0.8317\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 66us/sample - loss: 0.4924 - accuracy: 0.8317\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 66us/sample - loss: 0.4850 - accuracy: 0.8366\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 59us/sample - loss: 0.4770 - accuracy: 0.8366\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 933us/sample - loss: 0.5446 - accuracy: 0.7426\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7285 - accuracy: 0.4505\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.7116 - accuracy: 0.4505\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 52us/sample - loss: 0.6963 - accuracy: 0.4356\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.6830 - accuracy: 0.5198\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.6693 - accuracy: 0.6535\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.6594 - accuracy: 0.7178\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 41us/sample - loss: 0.6493 - accuracy: 0.7376\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.6415 - accuracy: 0.7129\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.6326 - accuracy: 0.7079\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.6248 - accuracy: 0.7030\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 43us/sample - loss: 0.6175 - accuracy: 0.7030\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.6105 - accuracy: 0.7178\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.6034 - accuracy: 0.7376\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.5970 - accuracy: 0.7426\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.5908 - accuracy: 0.7475\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 41us/sample - loss: 0.5846 - accuracy: 0.7525\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.5787 - accuracy: 0.7673\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.5726 - accuracy: 0.7673\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 46us/sample - loss: 0.5670 - accuracy: 0.7673\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.5615 - accuracy: 0.7673\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 899us/sample - loss: 0.5463 - accuracy: 0.8614\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7495 - accuracy: 0.3614\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 52us/sample - loss: 0.7373 - accuracy: 0.3713\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.7257 - accuracy: 0.3713\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 49us/sample - loss: 0.7161 - accuracy: 0.3911\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.7069 - accuracy: 0.4307\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.6977 - accuracy: 0.5297\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 60us/sample - loss: 0.6892 - accuracy: 0.5941\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6807 - accuracy: 0.6287\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.6730 - accuracy: 0.6584\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 49us/sample - loss: 0.6646 - accuracy: 0.6733\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.6572 - accuracy: 0.7030\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.6495 - accuracy: 0.7178\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.6425 - accuracy: 0.7228\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.6354 - accuracy: 0.7426\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 43us/sample - loss: 0.6288 - accuracy: 0.7673\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 49us/sample - loss: 0.6223 - accuracy: 0.7624\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.6157 - accuracy: 0.7624\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 48us/sample - loss: 0.6094 - accuracy: 0.7624\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 49us/sample - loss: 0.6034 - accuracy: 0.7673\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.5974 - accuracy: 0.7772\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 924us/sample - loss: 0.5976 - accuracy: 0.7426\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7010 - accuracy: 0.4950\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 46us/sample - loss: 0.6841 - accuracy: 0.5396\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.6695 - accuracy: 0.5891\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 43us/sample - loss: 0.6584 - accuracy: 0.6188\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.6489 - accuracy: 0.6634\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 47us/sample - loss: 0.6400 - accuracy: 0.7079\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 53us/sample - loss: 0.6326 - accuracy: 0.7079\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 57us/sample - loss: 0.6255 - accuracy: 0.7228\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 43us/sample - loss: 0.6188 - accuracy: 0.7228\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.6123 - accuracy: 0.7228\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.6063 - accuracy: 0.7376\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 40us/sample - loss: 0.6002 - accuracy: 0.7376\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 48us/sample - loss: 0.5943 - accuracy: 0.7376\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 54us/sample - loss: 0.5888 - accuracy: 0.7376\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 49us/sample - loss: 0.5827 - accuracy: 0.7475\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 58us/sample - loss: 0.5779 - accuracy: 0.7525\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.5720 - accuracy: 0.7525\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 57us/sample - loss: 0.5667 - accuracy: 0.7624\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.5616 - accuracy: 0.7673\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.5563 - accuracy: 0.7723\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.5923 - accuracy: 0.6634\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7098 - accuracy: 0.4554\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.6986 - accuracy: 0.4604\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.6904 - accuracy: 0.5347\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 37us/sample - loss: 0.6832 - accuracy: 0.5594\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 40us/sample - loss: 0.6752 - accuracy: 0.5990\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.6690 - accuracy: 0.6089\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6636 - accuracy: 0.6337\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6572 - accuracy: 0.6782\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.6522 - accuracy: 0.7228\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 35us/sample - loss: 0.6467 - accuracy: 0.7327\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.6424 - accuracy: 0.7624\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.6372 - accuracy: 0.7673\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.6329 - accuracy: 0.7673\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 49us/sample - loss: 0.6282 - accuracy: 0.7574\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.6235 - accuracy: 0.7624\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.6188 - accuracy: 0.7723\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 37us/sample - loss: 0.6144 - accuracy: 0.7772\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.6099 - accuracy: 0.7871\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.6054 - accuracy: 0.7921\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6010 - accuracy: 0.7921\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.5983 - accuracy: 0.8515\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6946 - accuracy: 0.4901\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 41us/sample - loss: 0.6838 - accuracy: 0.5198\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 47us/sample - loss: 0.6744 - accuracy: 0.5495\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.6652 - accuracy: 0.5842\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 48us/sample - loss: 0.6571 - accuracy: 0.5891\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.6493 - accuracy: 0.6040\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.6418 - accuracy: 0.6485\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 40us/sample - loss: 0.6350 - accuracy: 0.6881\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 70us/sample - loss: 0.6286 - accuracy: 0.7178\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.6226 - accuracy: 0.7426\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.6174 - accuracy: 0.7525\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 41us/sample - loss: 0.6114 - accuracy: 0.7426\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 48us/sample - loss: 0.6057 - accuracy: 0.7475\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.6002 - accuracy: 0.7525\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.5949 - accuracy: 0.7624\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 31us/sample - loss: 0.5895 - accuracy: 0.7624\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 30us/sample - loss: 0.5843 - accuracy: 0.7673\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.5790 - accuracy: 0.7673\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.5737 - accuracy: 0.7822\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 31us/sample - loss: 0.5685 - accuracy: 0.7822\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.5935 - accuracy: 0.7228\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6786 - accuracy: 0.5743\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 49us/sample - loss: 0.6686 - accuracy: 0.5743\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 40us/sample - loss: 0.6599 - accuracy: 0.5743\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 52us/sample - loss: 0.6520 - accuracy: 0.5743\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 37us/sample - loss: 0.6445 - accuracy: 0.5743\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 43us/sample - loss: 0.6382 - accuracy: 0.5743\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 31us/sample - loss: 0.6312 - accuracy: 0.5941\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.6249 - accuracy: 0.6139\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.6183 - accuracy: 0.6683\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6121 - accuracy: 0.6832\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.6057 - accuracy: 0.7079\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.5997 - accuracy: 0.7178\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 49us/sample - loss: 0.5935 - accuracy: 0.7228\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.5872 - accuracy: 0.7475\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.5814 - accuracy: 0.7871\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 35us/sample - loss: 0.5753 - accuracy: 0.7970\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.5698 - accuracy: 0.7970\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.5639 - accuracy: 0.8119\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.5581 - accuracy: 0.8168\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.5526 - accuracy: 0.8119\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 959us/sample - loss: 0.5923 - accuracy: 0.7129\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7348 - accuracy: 0.3317\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.7239 - accuracy: 0.3762\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.7162 - accuracy: 0.4604\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.7094 - accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 31us/sample - loss: 0.7027 - accuracy: 0.5099\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.6967 - accuracy: 0.5495\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.6909 - accuracy: 0.6238\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 37us/sample - loss: 0.6849 - accuracy: 0.6337\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.6797 - accuracy: 0.6485\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6753 - accuracy: 0.6535\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.6713 - accuracy: 0.6584\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.6672 - accuracy: 0.6832\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.6637 - accuracy: 0.6832\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 35us/sample - loss: 0.6610 - accuracy: 0.6881\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 37us/sample - loss: 0.6585 - accuracy: 0.6881\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 35us/sample - loss: 0.6568 - accuracy: 0.6832\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.6551 - accuracy: 0.6584\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.6523 - accuracy: 0.6584\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6487 - accuracy: 0.6634\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.6451 - accuracy: 0.6683\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 908us/sample - loss: 0.6048 - accuracy: 0.7624\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7306 - accuracy: 0.3960\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.7237 - accuracy: 0.3911\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 40us/sample - loss: 0.7184 - accuracy: 0.4010\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.7132 - accuracy: 0.3960\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 40us/sample - loss: 0.7090 - accuracy: 0.4257\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.7043 - accuracy: 0.4356\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 40us/sample - loss: 0.6998 - accuracy: 0.4455\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.6952 - accuracy: 0.4505\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 37us/sample - loss: 0.6908 - accuracy: 0.4703\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.6867 - accuracy: 0.5149\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.6825 - accuracy: 0.5545\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 37us/sample - loss: 0.6785 - accuracy: 0.5792\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.6742 - accuracy: 0.5990\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.6700 - accuracy: 0.6188\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.6659 - accuracy: 0.6485\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.6614 - accuracy: 0.6782\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 37us/sample - loss: 0.6568 - accuracy: 0.6733\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 35us/sample - loss: 0.6523 - accuracy: 0.6733\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.6477 - accuracy: 0.6782\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 37us/sample - loss: 0.6432 - accuracy: 0.6931\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.6643 - accuracy: 0.6436\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7401 - accuracy: 0.3614\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 48us/sample - loss: 0.7293 - accuracy: 0.3812\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 43us/sample - loss: 0.7205 - accuracy: 0.3960\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 53us/sample - loss: 0.7140 - accuracy: 0.3812\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 47us/sample - loss: 0.7081 - accuracy: 0.4208\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.7031 - accuracy: 0.4703\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.6987 - accuracy: 0.5099\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 40us/sample - loss: 0.6947 - accuracy: 0.5347\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 43us/sample - loss: 0.6908 - accuracy: 0.5644\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.6873 - accuracy: 0.5792\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 43us/sample - loss: 0.6837 - accuracy: 0.5644\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.6802 - accuracy: 0.5644\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 35us/sample - loss: 0.6767 - accuracy: 0.5644\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.6734 - accuracy: 0.5693\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.6702 - accuracy: 0.5693\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6670 - accuracy: 0.5743\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 37us/sample - loss: 0.6636 - accuracy: 0.5743\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6607 - accuracy: 0.5743\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 31us/sample - loss: 0.6575 - accuracy: 0.5792\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.6546 - accuracy: 0.5743\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.6570 - accuracy: 0.5446\n",
      "Train on 303 samples\n",
      "Epoch 1/20\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 0.6298 - accuracy: 0.7558\n",
      "Epoch 2/20\n",
      "303/303 [==============================] - 0s 145us/sample - loss: 0.5878 - accuracy: 0.7822\n",
      "Epoch 3/20\n",
      "303/303 [==============================] - 0s 163us/sample - loss: 0.5542 - accuracy: 0.7888\n",
      "Epoch 4/20\n",
      "303/303 [==============================] - 0s 156us/sample - loss: 0.5263 - accuracy: 0.8086\n",
      "Epoch 5/20\n",
      "303/303 [==============================] - 0s 200us/sample - loss: 0.5038 - accuracy: 0.8218\n",
      "Epoch 6/20\n",
      "303/303 [==============================] - 0s 156us/sample - loss: 0.4841 - accuracy: 0.7789\n",
      "Epoch 7/20\n",
      "303/303 [==============================] - 0s 219us/sample - loss: 0.4647 - accuracy: 0.8152\n",
      "Epoch 8/20\n",
      "303/303 [==============================] - 0s 205us/sample - loss: 0.4504 - accuracy: 0.8251\n",
      "Epoch 9/20\n",
      "303/303 [==============================] - 0s 221us/sample - loss: 0.4400 - accuracy: 0.8119\n",
      "Epoch 10/20\n",
      "303/303 [==============================] - 0s 175us/sample - loss: 0.4287 - accuracy: 0.8317\n",
      "Epoch 11/20\n",
      "303/303 [==============================] - 0s 181us/sample - loss: 0.4221 - accuracy: 0.8251\n",
      "Epoch 12/20\n",
      "303/303 [==============================] - 0s 156us/sample - loss: 0.4153 - accuracy: 0.8251\n",
      "Epoch 13/20\n",
      "303/303 [==============================] - 0s 171us/sample - loss: 0.4085 - accuracy: 0.8218\n",
      "Epoch 14/20\n",
      "303/303 [==============================] - 0s 168us/sample - loss: 0.4028 - accuracy: 0.8317\n",
      "Epoch 15/20\n",
      "303/303 [==============================] - 0s 155us/sample - loss: 0.3980 - accuracy: 0.8416\n",
      "Epoch 16/20\n",
      "303/303 [==============================] - 0s 158us/sample - loss: 0.3951 - accuracy: 0.8317\n",
      "Epoch 17/20\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6537 - accuracy: 0.70 - 0s 164us/sample - loss: 0.3898 - accuracy: 0.8350\n",
      "Epoch 18/20\n",
      "303/303 [==============================] - 0s 148us/sample - loss: 0.3870 - accuracy: 0.8383\n",
      "Epoch 19/20\n",
      "303/303 [==============================] - 0s 155us/sample - loss: 0.3846 - accuracy: 0.8284\n",
      "Epoch 20/20\n",
      "303/303 [==============================] - 0s 240us/sample - loss: 0.3821 - accuracy: 0.8350\n",
      "Best: 0.7986798683802286 using {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.7986798683802286, Stdev: 0.0373389608159633 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.7920792102813721, Stdev: 0.04042061077191993 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.7986798683802286, Stdev: 0.048728774455357206 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.7557755708694458, Stdev: 0.08137840098815666 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.7623762488365173, Stdev: 0.06313901243626734 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.6501650214195251, Stdev: 0.0890477711927088 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 132\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=True)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [20]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_2, y_2)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7846 - accuracy: 0.4554\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 168us/sample - loss: 0.7193 - accuracy: 0.4802\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.6906 - accuracy: 0.5495\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.6675 - accuracy: 0.5545\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.6487 - accuracy: 0.6733\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.6277 - accuracy: 0.7327\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.6086 - accuracy: 0.7525\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.5895 - accuracy: 0.7673\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.5698 - accuracy: 0.7822\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.5490 - accuracy: 0.7772\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.5297 - accuracy: 0.8020\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 189us/sample - loss: 0.5189 - accuracy: 0.8020\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.5029 - accuracy: 0.7921\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.4878 - accuracy: 0.8069\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.4769 - accuracy: 0.8119\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.4693 - accuracy: 0.8168\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.4613 - accuracy: 0.7970\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.4529 - accuracy: 0.8119\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.4472 - accuracy: 0.8168\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.4419 - accuracy: 0.8218\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.2386 - accuracy: 0.8812\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 4ms/sample - loss: 0.6720 - accuracy: 0.5545\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.6265 - accuracy: 0.7624\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.5960 - accuracy: 0.7871\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.5684 - accuracy: 0.8218\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.5425 - accuracy: 0.8218\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.5204 - accuracy: 0.7970\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 156us/sample - loss: 0.4999 - accuracy: 0.8168\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.4812 - accuracy: 0.8119\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4672 - accuracy: 0.8267\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.4530 - accuracy: 0.8119\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4404 - accuracy: 0.8218\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4348 - accuracy: 0.8317\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4209 - accuracy: 0.8119\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4125 - accuracy: 0.8267\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.4079 - accuracy: 0.8317\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.4013 - accuracy: 0.8267\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.3955 - accuracy: 0.8317\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.3920 - accuracy: 0.8267\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.3896 - accuracy: 0.8366\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.3843 - accuracy: 0.8317\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3417 - accuracy: 0.8119\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6330 - accuracy: 0.6485\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.6001 - accuracy: 0.7574\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.5714 - accuracy: 0.7970\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 153us/sample - loss: 0.5426 - accuracy: 0.8168\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.5185 - accuracy: 0.8218\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 169us/sample - loss: 0.4956 - accuracy: 0.8317\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.4755 - accuracy: 0.8416\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.4575 - accuracy: 0.8168\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4425 - accuracy: 0.8317\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.4302 - accuracy: 0.8317\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.4190 - accuracy: 0.8465\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.4119 - accuracy: 0.8416\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.4073 - accuracy: 0.8564\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.3968 - accuracy: 0.8515\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.3920 - accuracy: 0.8465\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.3881 - accuracy: 0.8614\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.3840 - accuracy: 0.8515\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 150us/sample - loss: 0.3789 - accuracy: 0.8614\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 156us/sample - loss: 0.3715 - accuracy: 0.8515\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.3721 - accuracy: 0.8614\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.4636 - accuracy: 0.7723\n",
      "Train on 202 samples\n",
      "Epoch 1/30\n",
      "202/202 [==============================] - 1s 4ms/sample - loss: 0.7253 - accuracy: 0.4554\n",
      "Epoch 2/30\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.6573 - accuracy: 0.6238\n",
      "Epoch 3/30\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.6190 - accuracy: 0.7525\n",
      "Epoch 4/30\n",
      "202/202 [==============================] - 0s 194us/sample - loss: 0.5919 - accuracy: 0.7624\n",
      "Epoch 5/30\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.5700 - accuracy: 0.7921\n",
      "Epoch 6/30\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.5511 - accuracy: 0.7822\n",
      "Epoch 7/30\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.5341 - accuracy: 0.7822\n",
      "Epoch 8/30\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.5174 - accuracy: 0.7871\n",
      "Epoch 9/30\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.5044 - accuracy: 0.7871\n",
      "Epoch 10/30\n",
      "202/202 [==============================] - 0s 218us/sample - loss: 0.4915 - accuracy: 0.7970\n",
      "Epoch 11/30\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.4819 - accuracy: 0.7970\n",
      "Epoch 12/30\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.4726 - accuracy: 0.8069\n",
      "Epoch 13/30\n",
      "202/202 [==============================] - 0s 183us/sample - loss: 0.4617 - accuracy: 0.8119\n",
      "Epoch 14/30\n",
      "202/202 [==============================] - 0s 183us/sample - loss: 0.4527 - accuracy: 0.8119\n",
      "Epoch 15/30\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.4479 - accuracy: 0.8168\n",
      "Epoch 16/30\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.4414 - accuracy: 0.8168\n",
      "Epoch 17/30\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.4357 - accuracy: 0.8119\n",
      "Epoch 18/30\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.4313 - accuracy: 0.8168\n",
      "Epoch 19/30\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.4269 - accuracy: 0.8218\n",
      "Epoch 20/30\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4227 - accuracy: 0.8119\n",
      "Epoch 21/30\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.4176 - accuracy: 0.8267\n",
      "Epoch 22/30\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.4160 - accuracy: 0.8267\n",
      "Epoch 23/30\n",
      "202/202 [==============================] - 0s 221us/sample - loss: 0.4124 - accuracy: 0.8416\n",
      "Epoch 24/30\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.4098 - accuracy: 0.8515\n",
      "Epoch 25/30\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.4072 - accuracy: 0.8317\n",
      "Epoch 26/30\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.4038 - accuracy: 0.8366\n",
      "Epoch 27/30\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.4017 - accuracy: 0.8515\n",
      "Epoch 28/30\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4003 - accuracy: 0.8416\n",
      "Epoch 29/30\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.3982 - accuracy: 0.8465\n",
      "Epoch 30/30\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.3967 - accuracy: 0.8416\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.1986 - accuracy: 0.8416\n",
      "Train on 202 samples\n",
      "Epoch 1/30\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7027 - accuracy: 0.4356\n",
      "Epoch 2/30\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.6691 - accuracy: 0.6584\n",
      "Epoch 3/30\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.6423 - accuracy: 0.7277\n",
      "Epoch 4/30\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.6181 - accuracy: 0.7772\n",
      "Epoch 5/30\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.5940 - accuracy: 0.7871\n",
      "Epoch 6/30\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.5734 - accuracy: 0.7871\n",
      "Epoch 7/30\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.5468 - accuracy: 0.7970\n",
      "Epoch 8/30\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.5207 - accuracy: 0.8069\n",
      "Epoch 9/30\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.5009 - accuracy: 0.7822\n",
      "Epoch 10/30\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.4823 - accuracy: 0.7822\n",
      "Epoch 11/30\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.4707 - accuracy: 0.8119\n",
      "Epoch 12/30\n",
      "202/202 [==============================] - 0s 234us/sample - loss: 0.4583 - accuracy: 0.7921\n",
      "Epoch 13/30\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.4459 - accuracy: 0.8020\n",
      "Epoch 14/30\n",
      "202/202 [==============================] - 0s 203us/sample - loss: 0.4366 - accuracy: 0.7921\n",
      "Epoch 15/30\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.4288 - accuracy: 0.8020\n",
      "Epoch 16/30\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.4219 - accuracy: 0.8069\n",
      "Epoch 17/30\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.4156 - accuracy: 0.8069\n",
      "Epoch 18/30\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.4110 - accuracy: 0.8168\n",
      "Epoch 19/30\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4035 - accuracy: 0.8168\n",
      "Epoch 20/30\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.4020 - accuracy: 0.8069\n",
      "Epoch 21/30\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.3981 - accuracy: 0.8069\n",
      "Epoch 22/30\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3927 - accuracy: 0.8267\n",
      "Epoch 23/30\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3892 - accuracy: 0.8267\n",
      "Epoch 24/30\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.3858 - accuracy: 0.8218\n",
      "Epoch 25/30\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.3840 - accuracy: 0.8267\n",
      "Epoch 26/30\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.3797 - accuracy: 0.8218\n",
      "Epoch 27/30\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.3793 - accuracy: 0.8218\n",
      "Epoch 28/30\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.3751 - accuracy: 0.8317\n",
      "Epoch 29/30\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.3736 - accuracy: 0.8317\n",
      "Epoch 30/30\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.3732 - accuracy: 0.8416\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3550 - accuracy: 0.8020\n",
      "Train on 202 samples\n",
      "Epoch 1/30\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7077 - accuracy: 0.5743\n",
      "Epoch 2/30\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.6710 - accuracy: 0.5842\n",
      "Epoch 3/30\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.6406 - accuracy: 0.5990\n",
      "Epoch 4/30\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.6128 - accuracy: 0.6584\n",
      "Epoch 5/30\n",
      "202/202 [==============================] - 0s 168us/sample - loss: 0.5837 - accuracy: 0.7426\n",
      "Epoch 6/30\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.5581 - accuracy: 0.8069\n",
      "Epoch 7/30\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.5326 - accuracy: 0.8515\n",
      "Epoch 8/30\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.5086 - accuracy: 0.8614\n",
      "Epoch 9/30\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.4882 - accuracy: 0.8515\n",
      "Epoch 10/30\n",
      "202/202 [==============================] - 0s 145us/sample - loss: 0.4693 - accuracy: 0.8515\n",
      "Epoch 11/30\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.4503 - accuracy: 0.8614\n",
      "Epoch 12/30\n",
      "202/202 [==============================] - 0s 151us/sample - loss: 0.4379 - accuracy: 0.8663\n",
      "Epoch 13/30\n",
      "202/202 [==============================] - 0s 151us/sample - loss: 0.4257 - accuracy: 0.8614\n",
      "Epoch 14/30\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.4160 - accuracy: 0.8762\n",
      "Epoch 15/30\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.4074 - accuracy: 0.8564\n",
      "Epoch 16/30\n",
      "202/202 [==============================] - 0s 151us/sample - loss: 0.3988 - accuracy: 0.8762\n",
      "Epoch 17/30\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.3930 - accuracy: 0.8614\n",
      "Epoch 18/30\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.3885 - accuracy: 0.8614\n",
      "Epoch 19/30\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.3831 - accuracy: 0.8713\n",
      "Epoch 20/30\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.3796 - accuracy: 0.8663\n",
      "Epoch 21/30\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.3776 - accuracy: 0.8812\n",
      "Epoch 22/30\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.3725 - accuracy: 0.8614\n",
      "Epoch 23/30\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.3716 - accuracy: 0.8663\n",
      "Epoch 24/30\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.3658 - accuracy: 0.8663\n",
      "Epoch 25/30\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.3642 - accuracy: 0.8614\n",
      "Epoch 26/30\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.3653 - accuracy: 0.8614\n",
      "Epoch 27/30\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.3606 - accuracy: 0.8663\n",
      "Epoch 28/30\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.3578 - accuracy: 0.8663\n",
      "Epoch 29/30\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.3571 - accuracy: 0.8713\n",
      "Epoch 30/30\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.3557 - accuracy: 0.8663\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.4141 - accuracy: 0.7921\n",
      "Train on 202 samples\n",
      "Epoch 1/40\n",
      "202/202 [==============================] - 1s 4ms/sample - loss: 0.6568 - accuracy: 0.5693\n",
      "Epoch 2/40\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.6362 - accuracy: 0.7277\n",
      "Epoch 3/40\n",
      "202/202 [==============================] - 0s 169us/sample - loss: 0.6146 - accuracy: 0.7624\n",
      "Epoch 4/40\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.5938 - accuracy: 0.7673\n",
      "Epoch 5/40\n",
      "202/202 [==============================] - 0s 194us/sample - loss: 0.5752 - accuracy: 0.7822\n",
      "Epoch 6/40\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.5582 - accuracy: 0.7723\n",
      "Epoch 7/40\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.5421 - accuracy: 0.7772\n",
      "Epoch 8/40\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.5276 - accuracy: 0.7723\n",
      "Epoch 9/40\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.5163 - accuracy: 0.7970\n",
      "Epoch 10/40\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.5017 - accuracy: 0.7921\n",
      "Epoch 11/40\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.4915 - accuracy: 0.7970\n",
      "Epoch 12/40\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.4809 - accuracy: 0.7970\n",
      "Epoch 13/40\n",
      "202/202 [==============================] - 0s 605us/sample - loss: 0.4723 - accuracy: 0.8020\n",
      "Epoch 14/40\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.4628 - accuracy: 0.8069\n",
      "Epoch 15/40\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.4569 - accuracy: 0.8020\n",
      "Epoch 16/40\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4485 - accuracy: 0.8168\n",
      "Epoch 17/40\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.4441 - accuracy: 0.8119\n",
      "Epoch 18/40\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.4390 - accuracy: 0.8168\n",
      "Epoch 19/40\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.4363 - accuracy: 0.8168\n",
      "Epoch 20/40\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.4285 - accuracy: 0.8119\n",
      "Epoch 21/40\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.4292 - accuracy: 0.8168\n",
      "Epoch 22/40\n",
      "202/202 [==============================] - 0s 169us/sample - loss: 0.4209 - accuracy: 0.8168\n",
      "Epoch 23/40\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4177 - accuracy: 0.8168\n",
      "Epoch 24/40\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.4152 - accuracy: 0.8218\n",
      "Epoch 25/40\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4152 - accuracy: 0.8317\n",
      "Epoch 26/40\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.4090 - accuracy: 0.8317\n",
      "Epoch 27/40\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.4088 - accuracy: 0.8218\n",
      "Epoch 28/40\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.4068 - accuracy: 0.8168\n",
      "Epoch 29/40\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.4050 - accuracy: 0.8218\n",
      "Epoch 30/40\n",
      "202/202 [==============================] - 0s 156us/sample - loss: 0.4039 - accuracy: 0.8416\n",
      "Epoch 31/40\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.4028 - accuracy: 0.8267\n",
      "Epoch 32/40\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.3996 - accuracy: 0.8317\n",
      "Epoch 33/40\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.3993 - accuracy: 0.8317\n",
      "Epoch 34/40\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.3971 - accuracy: 0.8416\n",
      "Epoch 35/40\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.3960 - accuracy: 0.8416\n",
      "Epoch 36/40\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.3971 - accuracy: 0.8416\n",
      "Epoch 37/40\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.3944 - accuracy: 0.8366\n",
      "Epoch 38/40\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.3974 - accuracy: 0.8366\n",
      "Epoch 39/40\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.3901 - accuracy: 0.8515\n",
      "Epoch 40/40\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.3898 - accuracy: 0.8465\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.1905 - accuracy: 0.8614\n",
      "Train on 202 samples\n",
      "Epoch 1/40\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6448 - accuracy: 0.6980\n",
      "Epoch 2/40\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.6097 - accuracy: 0.7277\n",
      "Epoch 3/40\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.5779 - accuracy: 0.7871\n",
      "Epoch 4/40\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.5512 - accuracy: 0.7871\n",
      "Epoch 5/40\n",
      "202/202 [==============================] - 0s 183us/sample - loss: 0.5295 - accuracy: 0.7970\n",
      "Epoch 6/40\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.5119 - accuracy: 0.7970\n",
      "Epoch 7/40\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.4943 - accuracy: 0.8069\n",
      "Epoch 8/40\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.4774 - accuracy: 0.8168\n",
      "Epoch 9/40\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.4627 - accuracy: 0.8119\n",
      "Epoch 10/40\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.4551 - accuracy: 0.8168\n",
      "Epoch 11/40\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.4438 - accuracy: 0.8069\n",
      "Epoch 12/40\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.4323 - accuracy: 0.8168\n",
      "Epoch 13/40\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.4257 - accuracy: 0.8119\n",
      "Epoch 14/40\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.4180 - accuracy: 0.8069\n",
      "Epoch 15/40\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.4130 - accuracy: 0.8218\n",
      "Epoch 16/40\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.4080 - accuracy: 0.8267\n",
      "Epoch 17/40\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4014 - accuracy: 0.8416\n",
      "Epoch 18/40\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.3983 - accuracy: 0.8218\n",
      "Epoch 19/40\n",
      "202/202 [==============================] - 0s 148us/sample - loss: 0.3953 - accuracy: 0.8218\n",
      "Epoch 20/40\n",
      "202/202 [==============================] - 0s 156us/sample - loss: 0.3914 - accuracy: 0.8267\n",
      "Epoch 21/40\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.3883 - accuracy: 0.8218\n",
      "Epoch 22/40\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.3862 - accuracy: 0.8317\n",
      "Epoch 23/40\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.3836 - accuracy: 0.8366\n",
      "Epoch 24/40\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.3813 - accuracy: 0.8168\n",
      "Epoch 25/40\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.3777 - accuracy: 0.8267\n",
      "Epoch 26/40\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.3750 - accuracy: 0.8366\n",
      "Epoch 27/40\n",
      "202/202 [==============================] - 0s 150us/sample - loss: 0.3782 - accuracy: 0.8069\n",
      "Epoch 28/40\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.3732 - accuracy: 0.8465\n",
      "Epoch 29/40\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.3727 - accuracy: 0.8366\n",
      "Epoch 30/40\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.3722 - accuracy: 0.8515\n",
      "Epoch 31/40\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.3681 - accuracy: 0.8366\n",
      "Epoch 32/40\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.3655 - accuracy: 0.8366\n",
      "Epoch 33/40\n",
      "202/202 [==============================] - 0s 183us/sample - loss: 0.3660 - accuracy: 0.8515\n",
      "Epoch 34/40\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.3631 - accuracy: 0.8366\n",
      "Epoch 35/40\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.3603 - accuracy: 0.8465\n",
      "Epoch 36/40\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.3618 - accuracy: 0.8366\n",
      "Epoch 37/40\n",
      "202/202 [==============================] - 0s 155us/sample - loss: 0.3593 - accuracy: 0.8465\n",
      "Epoch 38/40\n",
      "202/202 [==============================] - 0s 155us/sample - loss: 0.3567 - accuracy: 0.8515\n",
      "Epoch 39/40\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.3556 - accuracy: 0.8416\n",
      "Epoch 40/40\n",
      "202/202 [==============================] - 0s 150us/sample - loss: 0.3548 - accuracy: 0.8416\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 966us/sample - loss: 0.3233 - accuracy: 0.8317\n",
      "Train on 202 samples\n",
      "Epoch 1/40\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6783 - accuracy: 0.6089\n",
      "Epoch 2/40\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.6449 - accuracy: 0.7327\n",
      "Epoch 3/40\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.6132 - accuracy: 0.7970\n",
      "Epoch 4/40\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.5839 - accuracy: 0.8317\n",
      "Epoch 5/40\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.5565 - accuracy: 0.8515\n",
      "Epoch 6/40\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.5314 - accuracy: 0.8663\n",
      "Epoch 7/40\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.5083 - accuracy: 0.8713\n",
      "Epoch 8/40\n",
      "202/202 [==============================] - 0s 155us/sample - loss: 0.4874 - accuracy: 0.8515\n",
      "Epoch 9/40\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.4693 - accuracy: 0.8564\n",
      "Epoch 10/40\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.4524 - accuracy: 0.8713\n",
      "Epoch 11/40\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.4392 - accuracy: 0.8663\n",
      "Epoch 12/40\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.4295 - accuracy: 0.8564\n",
      "Epoch 13/40\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.4165 - accuracy: 0.8614\n",
      "Epoch 14/40\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.4090 - accuracy: 0.8663\n",
      "Epoch 15/40\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.4002 - accuracy: 0.8614\n",
      "Epoch 16/40\n",
      "202/202 [==============================] - 0s 168us/sample - loss: 0.3931 - accuracy: 0.8663\n",
      "Epoch 17/40\n",
      "202/202 [==============================] - 0s 156us/sample - loss: 0.3863 - accuracy: 0.8663\n",
      "Epoch 18/40\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.3820 - accuracy: 0.8663\n",
      "Epoch 19/40\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.3771 - accuracy: 0.8663\n",
      "Epoch 20/40\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.3743 - accuracy: 0.8663\n",
      "Epoch 21/40\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.3707 - accuracy: 0.8663\n",
      "Epoch 22/40\n",
      "202/202 [==============================] - 0s 194us/sample - loss: 0.3677 - accuracy: 0.8663\n",
      "Epoch 23/40\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.3640 - accuracy: 0.8614\n",
      "Epoch 24/40\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.3626 - accuracy: 0.8663\n",
      "Epoch 25/40\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.3621 - accuracy: 0.8564\n",
      "Epoch 26/40\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.3577 - accuracy: 0.8614\n",
      "Epoch 27/40\n",
      "202/202 [==============================] - 0s 208us/sample - loss: 0.3572 - accuracy: 0.8762\n",
      "Epoch 28/40\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.3537 - accuracy: 0.8663\n",
      "Epoch 29/40\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.3539 - accuracy: 0.8564\n",
      "Epoch 30/40\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.3516 - accuracy: 0.8614\n",
      "Epoch 31/40\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.3513 - accuracy: 0.8564\n",
      "Epoch 32/40\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.3482 - accuracy: 0.8614\n",
      "Epoch 33/40\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.3468 - accuracy: 0.8614\n",
      "Epoch 34/40\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.3462 - accuracy: 0.8614\n",
      "Epoch 35/40\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.3457 - accuracy: 0.8713\n",
      "Epoch 36/40\n",
      "202/202 [==============================] - 0s 189us/sample - loss: 0.3468 - accuracy: 0.8713\n",
      "Epoch 37/40\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.3436 - accuracy: 0.8663\n",
      "Epoch 38/40\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.3447 - accuracy: 0.8713\n",
      "Epoch 39/40\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.3411 - accuracy: 0.8713\n",
      "Epoch 40/40\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.3407 - accuracy: 0.8713\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.4209 - accuracy: 0.7723\n",
      "Train on 202 samples\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7001 - accuracy: 0.4851\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 151us/sample - loss: 0.6766 - accuracy: 0.6188\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.6566 - accuracy: 0.6931\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 150us/sample - loss: 0.6348 - accuracy: 0.7228\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.6130 - accuracy: 0.7475\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.5919 - accuracy: 0.7228\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 156us/sample - loss: 0.5736 - accuracy: 0.7376\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.5574 - accuracy: 0.7525\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.5414 - accuracy: 0.7525\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.5287 - accuracy: 0.7525\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.5158 - accuracy: 0.7772\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.5036 - accuracy: 0.7822\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.4922 - accuracy: 0.7822\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 231us/sample - loss: 0.4869 - accuracy: 0.7970\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.4761 - accuracy: 0.8020\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4708 - accuracy: 0.8119\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 153us/sample - loss: 0.4602 - accuracy: 0.8069\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 155us/sample - loss: 0.4542 - accuracy: 0.7970\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.4477 - accuracy: 0.8069\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4434 - accuracy: 0.8069\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.4379 - accuracy: 0.8119\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.4330 - accuracy: 0.8069\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 183us/sample - loss: 0.4314 - accuracy: 0.8168\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.4267 - accuracy: 0.8218\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.4231 - accuracy: 0.8218\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.4194 - accuracy: 0.8069\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.4204 - accuracy: 0.8366\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.4149 - accuracy: 0.8267\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4107 - accuracy: 0.8218\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.4092 - accuracy: 0.8267\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.4111 - accuracy: 0.8267\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4064 - accuracy: 0.8218\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.4033 - accuracy: 0.8218\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.4026 - accuracy: 0.8218\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.4004 - accuracy: 0.8267\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.4001 - accuracy: 0.8416\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.3993 - accuracy: 0.8267\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.3966 - accuracy: 0.8366\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.3962 - accuracy: 0.8267\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.3947 - accuracy: 0.8317\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.3931 - accuracy: 0.8416\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3919 - accuracy: 0.8416\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3915 - accuracy: 0.8416\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.3918 - accuracy: 0.8416\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.3893 - accuracy: 0.8267\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.3893 - accuracy: 0.8416\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.3892 - accuracy: 0.8465\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.3893 - accuracy: 0.8416\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 227us/sample - loss: 0.3873 - accuracy: 0.8515\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.3883 - accuracy: 0.8416\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.1839 - accuracy: 0.8515\n",
      "Train on 202 samples\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7723 - accuracy: 0.5149\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.6935 - accuracy: 0.5248\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.6496 - accuracy: 0.6881\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.6211 - accuracy: 0.7822\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.5908 - accuracy: 0.8119\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.5666 - accuracy: 0.8267\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.5443 - accuracy: 0.8119\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.5239 - accuracy: 0.8069\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.5090 - accuracy: 0.8020\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.4924 - accuracy: 0.8168\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.4771 - accuracy: 0.8069\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4643 - accuracy: 0.8020\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.4540 - accuracy: 0.8020\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.4441 - accuracy: 0.8119\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4362 - accuracy: 0.8168\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4279 - accuracy: 0.8020\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.4215 - accuracy: 0.8119\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.4172 - accuracy: 0.8069\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4116 - accuracy: 0.8119\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.4078 - accuracy: 0.8168\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.4041 - accuracy: 0.8218\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 447us/sample - loss: 0.4009 - accuracy: 0.8069\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.3988 - accuracy: 0.8168\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.3941 - accuracy: 0.8119\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.3917 - accuracy: 0.8119\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 146us/sample - loss: 0.3901 - accuracy: 0.8168\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 151us/sample - loss: 0.3885 - accuracy: 0.8218\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.3830 - accuracy: 0.8267\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 141us/sample - loss: 0.3825 - accuracy: 0.8267\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 155us/sample - loss: 0.3801 - accuracy: 0.8218\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.3784 - accuracy: 0.8317\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.3753 - accuracy: 0.8218\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.3759 - accuracy: 0.8218\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.3752 - accuracy: 0.8317\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.3717 - accuracy: 0.8267\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.3712 - accuracy: 0.8366\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 153us/sample - loss: 0.3696 - accuracy: 0.8317\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.3682 - accuracy: 0.8267\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.3686 - accuracy: 0.8366\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 169us/sample - loss: 0.3647 - accuracy: 0.8317\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 169us/sample - loss: 0.3649 - accuracy: 0.8317\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.3636 - accuracy: 0.8317\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 225us/sample - loss: 0.3632 - accuracy: 0.8317\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.3610 - accuracy: 0.8317\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.3610 - accuracy: 0.8366\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.3592 - accuracy: 0.8366\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.3603 - accuracy: 0.8267\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.3581 - accuracy: 0.8366\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 183us/sample - loss: 0.3591 - accuracy: 0.8465\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 203us/sample - loss: 0.3597 - accuracy: 0.8366\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3277 - accuracy: 0.8119\n",
      "Train on 202 samples\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6834 - accuracy: 0.5297\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.6350 - accuracy: 0.6881\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.6016 - accuracy: 0.7723\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.5719 - accuracy: 0.7921\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.5423 - accuracy: 0.8218\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.5248 - accuracy: 0.7970\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 153us/sample - loss: 0.5012 - accuracy: 0.8366\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.4828 - accuracy: 0.8366\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4660 - accuracy: 0.8317\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.4505 - accuracy: 0.8465\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.4377 - accuracy: 0.8416\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.4263 - accuracy: 0.8465\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 169us/sample - loss: 0.4168 - accuracy: 0.8416\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.4084 - accuracy: 0.8416\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4020 - accuracy: 0.8614\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.3957 - accuracy: 0.8564\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.3906 - accuracy: 0.8515\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.3839 - accuracy: 0.8515\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.3788 - accuracy: 0.8713\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 153us/sample - loss: 0.3757 - accuracy: 0.8762\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 148us/sample - loss: 0.3703 - accuracy: 0.8762\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.3671 - accuracy: 0.8564\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 149us/sample - loss: 0.3659 - accuracy: 0.8713\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 149us/sample - loss: 0.3626 - accuracy: 0.8614\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.3633 - accuracy: 0.8614\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.3590 - accuracy: 0.8614\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.3596 - accuracy: 0.8663\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.3536 - accuracy: 0.8614\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.3541 - accuracy: 0.8564\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.3508 - accuracy: 0.8564\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.3492 - accuracy: 0.8614\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.3481 - accuracy: 0.8614\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.3473 - accuracy: 0.8564\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.3468 - accuracy: 0.8614\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.3426 - accuracy: 0.8713\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.3500 - accuracy: 0.8663\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.3475 - accuracy: 0.8564\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.3445 - accuracy: 0.8614\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.3437 - accuracy: 0.8663\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.3411 - accuracy: 0.8713\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 155us/sample - loss: 0.3405 - accuracy: 0.8663\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.3388 - accuracy: 0.8713\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.3406 - accuracy: 0.8614\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.3440 - accuracy: 0.8713\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.3368 - accuracy: 0.8663\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.3393 - accuracy: 0.8663\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.3369 - accuracy: 0.8713\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.3359 - accuracy: 0.8663\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.3348 - accuracy: 0.8713\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 149us/sample - loss: 0.3337 - accuracy: 0.8713\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.4193 - accuracy: 0.7921\n",
      "Train on 303 samples\n",
      "Epoch 1/20\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 0.6091 - accuracy: 0.7624\n",
      "Epoch 2/20\n",
      "303/303 [==============================] - 0s 169us/sample - loss: 0.5756 - accuracy: 0.7756\n",
      "Epoch 3/20\n",
      "303/303 [==============================] - 0s 155us/sample - loss: 0.5457 - accuracy: 0.7987\n",
      "Epoch 4/20\n",
      "303/303 [==============================] - 0s 154us/sample - loss: 0.5214 - accuracy: 0.8218\n",
      "Epoch 5/20\n",
      "303/303 [==============================] - 0s 161us/sample - loss: 0.4975 - accuracy: 0.8251\n",
      "Epoch 6/20\n",
      "303/303 [==============================] - 0s 153us/sample - loss: 0.4767 - accuracy: 0.8251\n",
      "Epoch 7/20\n",
      "303/303 [==============================] - 0s 147us/sample - loss: 0.4572 - accuracy: 0.8317\n",
      "Epoch 8/20\n",
      "303/303 [==============================] - 0s 162us/sample - loss: 0.4421 - accuracy: 0.8251\n",
      "Epoch 9/20\n",
      "303/303 [==============================] - 0s 154us/sample - loss: 0.4302 - accuracy: 0.8284\n",
      "Epoch 10/20\n",
      "303/303 [==============================] - 0s 152us/sample - loss: 0.4204 - accuracy: 0.8218\n",
      "Epoch 11/20\n",
      "303/303 [==============================] - 0s 161us/sample - loss: 0.4122 - accuracy: 0.8449\n",
      "Epoch 12/20\n",
      "303/303 [==============================] - 0s 155us/sample - loss: 0.4048 - accuracy: 0.8383\n",
      "Epoch 13/20\n",
      "303/303 [==============================] - 0s 189us/sample - loss: 0.3993 - accuracy: 0.8383\n",
      "Epoch 14/20\n",
      "303/303 [==============================] - 0s 169us/sample - loss: 0.3934 - accuracy: 0.8383\n",
      "Epoch 15/20\n",
      "303/303 [==============================] - 0s 163us/sample - loss: 0.3899 - accuracy: 0.8383\n",
      "Epoch 16/20\n",
      "303/303 [==============================] - 0s 201us/sample - loss: 0.3866 - accuracy: 0.8350\n",
      "Epoch 17/20\n",
      "303/303 [==============================] - 0s 161us/sample - loss: 0.3830 - accuracy: 0.8383\n",
      "Epoch 18/20\n",
      "303/303 [==============================] - 0s 147us/sample - loss: 0.3850 - accuracy: 0.8350\n",
      "Epoch 19/20\n",
      "303/303 [==============================] - 0s 151us/sample - loss: 0.3775 - accuracy: 0.8449\n",
      "Epoch 20/20\n",
      "303/303 [==============================] - 0s 146us/sample - loss: 0.3752 - accuracy: 0.8449\n",
      "Best: 0.8217821717262268 using {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.8217821717262268, Stdev: 0.04501048723594382 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.8118811845779419, Stdev: 0.021388576788767738 with: {'batch_size': 10, 'epochs': 30}\n",
      "Means: 0.8217821717262268, Stdev: 0.0370461016997341 with: {'batch_size': 10, 'epochs': 40}\n",
      "Means: 0.8184818426767985, Stdev: 0.024697401133156067 with: {'batch_size': 10, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "# batch_size of 10 on 20 epochs appears to be the best, now I'll try again with a few different number of epochs. Then with a couple more\n",
    "# hidden layers in the next iteration.\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 132\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=13, activation='relu'))\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=True)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10],\n",
    "              'epochs': [20, 30, 40, 50]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_2, y_2)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6539 - accuracy: 0.6535\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.5986 - accuracy: 0.7624\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.5482 - accuracy: 0.7723\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 245us/sample - loss: 0.5037 - accuracy: 0.8020\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.4627 - accuracy: 0.8020\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.4436 - accuracy: 0.7970\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.4361 - accuracy: 0.7921\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.4173 - accuracy: 0.8020\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 225us/sample - loss: 0.4093 - accuracy: 0.8267\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.4051 - accuracy: 0.8218\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 245us/sample - loss: 0.3973 - accuracy: 0.8366\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.3940 - accuracy: 0.8317\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 283us/sample - loss: 0.3862 - accuracy: 0.8366\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.3940 - accuracy: 0.8416\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.3791 - accuracy: 0.8366\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.3855 - accuracy: 0.8317\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.3745 - accuracy: 0.8515\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.3747 - accuracy: 0.8416\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3663 - accuracy: 0.8416\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.3707 - accuracy: 0.8366\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.1795 - accuracy: 0.8515\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 5ms/sample - loss: 0.6764 - accuracy: 0.5446\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.6371 - accuracy: 0.7723\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.5805 - accuracy: 0.7871\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 203us/sample - loss: 0.5056 - accuracy: 0.7970\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.4491 - accuracy: 0.8119\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.4185 - accuracy: 0.8020\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 254us/sample - loss: 0.4009 - accuracy: 0.8119\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.3854 - accuracy: 0.8168\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.3790 - accuracy: 0.8218\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.3695 - accuracy: 0.8416\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.3676 - accuracy: 0.8267\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 225us/sample - loss: 0.3564 - accuracy: 0.8416\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.3479 - accuracy: 0.8366\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 227us/sample - loss: 0.3407 - accuracy: 0.8416\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.3391 - accuracy: 0.8366\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.3388 - accuracy: 0.8366\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.3334 - accuracy: 0.8366\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.3427 - accuracy: 0.8515\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.3208 - accuracy: 0.8614\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.3122 - accuracy: 0.8465\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3140 - accuracy: 0.8317\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6859 - accuracy: 0.5941\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.6389 - accuracy: 0.8119\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 203us/sample - loss: 0.5929 - accuracy: 0.7970\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.5327 - accuracy: 0.8267\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4832 - accuracy: 0.8119\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.4211 - accuracy: 0.8465\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3844 - accuracy: 0.8812\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 215us/sample - loss: 0.3716 - accuracy: 0.8614\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 228us/sample - loss: 0.3471 - accuracy: 0.8713\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 243us/sample - loss: 0.3349 - accuracy: 0.8762\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.3362 - accuracy: 0.8762\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.3283 - accuracy: 0.8762\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.3254 - accuracy: 0.8762\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.3201 - accuracy: 0.8713\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.3197 - accuracy: 0.8762\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.3141 - accuracy: 0.8812\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.3124 - accuracy: 0.8713\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.3077 - accuracy: 0.8812\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 328us/sample - loss: 0.3088 - accuracy: 0.8861 - loss: 0.2948 - accuracy: 0.88\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.3058 - accuracy: 0.8762\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3255 - accuracy: 0.8218\n",
      "Train on 202 samples\n",
      "Epoch 1/30\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6837 - accuracy: 0.5396\n",
      "Epoch 2/30\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.6493 - accuracy: 0.5891\n",
      "Epoch 3/30\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.6029 - accuracy: 0.7921\n",
      "Epoch 4/30\n",
      "202/202 [==============================] - 0s 223us/sample - loss: 0.5346 - accuracy: 0.7921\n",
      "Epoch 5/30\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.4741 - accuracy: 0.8020\n",
      "Epoch 6/30\n",
      "202/202 [==============================] - 0s 189us/sample - loss: 0.4332 - accuracy: 0.8119\n",
      "Epoch 7/30\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.4199 - accuracy: 0.8317\n",
      "Epoch 8/30\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.4045 - accuracy: 0.8317\n",
      "Epoch 9/30\n",
      "202/202 [==============================] - 0s 182us/sample - loss: 0.3931 - accuracy: 0.8416\n",
      "Epoch 10/30\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.3891 - accuracy: 0.8416\n",
      "Epoch 11/30\n",
      "202/202 [==============================] - 0s 231us/sample - loss: 0.3803 - accuracy: 0.8465\n",
      "Epoch 12/30\n",
      "202/202 [==============================] - 0s 228us/sample - loss: 0.3916 - accuracy: 0.8267\n",
      "Epoch 13/30\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3971 - accuracy: 0.8069\n",
      "Epoch 14/30\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.3832 - accuracy: 0.8317\n",
      "Epoch 15/30\n",
      "202/202 [==============================] - 0s 531us/sample - loss: 0.3753 - accuracy: 0.8317\n",
      "Epoch 16/30\n",
      "202/202 [==============================] - 0s 223us/sample - loss: 0.3720 - accuracy: 0.8366\n",
      "Epoch 17/30\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.3661 - accuracy: 0.8515\n",
      "Epoch 18/30\n",
      "202/202 [==============================] - 0s 228us/sample - loss: 0.3585 - accuracy: 0.8663\n",
      "Epoch 19/30\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.3580 - accuracy: 0.8564\n",
      "Epoch 20/30\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.3544 - accuracy: 0.8663\n",
      "Epoch 21/30\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.3586 - accuracy: 0.8416\n",
      "Epoch 22/30\n",
      "202/202 [==============================] - 0s 190us/sample - loss: 0.3669 - accuracy: 0.8218\n",
      "Epoch 23/30\n",
      "202/202 [==============================] - 0s 190us/sample - loss: 0.3500 - accuracy: 0.8564\n",
      "Epoch 24/30\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.3421 - accuracy: 0.8614\n",
      "Epoch 25/30\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3440 - accuracy: 0.8762\n",
      "Epoch 26/30\n",
      "202/202 [==============================] - 0s 227us/sample - loss: 0.3479 - accuracy: 0.8366\n",
      "Epoch 27/30\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.3380 - accuracy: 0.8762\n",
      "Epoch 28/30\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.3385 - accuracy: 0.8812\n",
      "Epoch 29/30\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.3367 - accuracy: 0.8812\n",
      "Epoch 30/30\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.3285 - accuracy: 0.8713\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.1798 - accuracy: 0.8713\n",
      "Train on 202 samples\n",
      "Epoch 1/30\n",
      "202/202 [==============================] - 1s 5ms/sample - loss: 0.6938 - accuracy: 0.5792\n",
      "Epoch 2/30\n",
      "202/202 [==============================] - 0s 228us/sample - loss: 0.6439 - accuracy: 0.7822\n",
      "Epoch 3/30\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.5984 - accuracy: 0.7970\n",
      "Epoch 4/30\n",
      "202/202 [==============================] - 0s 231us/sample - loss: 0.5424 - accuracy: 0.8119\n",
      "Epoch 5/30\n",
      "202/202 [==============================] - 0s 226us/sample - loss: 0.4852 - accuracy: 0.8119\n",
      "Epoch 6/30\n",
      "202/202 [==============================] - 0s 231us/sample - loss: 0.4452 - accuracy: 0.8069\n",
      "Epoch 7/30\n",
      "202/202 [==============================] - 0s 225us/sample - loss: 0.4137 - accuracy: 0.8168\n",
      "Epoch 8/30\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.3923 - accuracy: 0.8069\n",
      "Epoch 9/30\n",
      "202/202 [==============================] - 0s 208us/sample - loss: 0.3854 - accuracy: 0.8416\n",
      "Epoch 10/30\n",
      "202/202 [==============================] - 0s 208us/sample - loss: 0.3714 - accuracy: 0.8267\n",
      "Epoch 11/30\n",
      "202/202 [==============================] - 0s 229us/sample - loss: 0.3582 - accuracy: 0.8218\n",
      "Epoch 12/30\n",
      "202/202 [==============================] - 0s 226us/sample - loss: 0.3455 - accuracy: 0.8416\n",
      "Epoch 13/30\n",
      "202/202 [==============================] - 0s 228us/sample - loss: 0.3409 - accuracy: 0.8515\n",
      "Epoch 14/30\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.3377 - accuracy: 0.8416\n",
      "Epoch 15/30\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.3285 - accuracy: 0.8465\n",
      "Epoch 16/30\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.3393 - accuracy: 0.8614\n",
      "Epoch 17/30\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.3172 - accuracy: 0.8861\n",
      "Epoch 18/30\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.3219 - accuracy: 0.8713\n",
      "Epoch 19/30\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.3191 - accuracy: 0.8762\n",
      "Epoch 20/30\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.3175 - accuracy: 0.8614\n",
      "Epoch 21/30\n",
      "202/202 [==============================] - 0s 215us/sample - loss: 0.3187 - accuracy: 0.8713\n",
      "Epoch 22/30\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.2974 - accuracy: 0.8812\n",
      "Epoch 23/30\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.3005 - accuracy: 0.8861\n",
      "Epoch 24/30\n",
      "202/202 [==============================] - 0s 233us/sample - loss: 0.2951 - accuracy: 0.8762\n",
      "Epoch 25/30\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.2859 - accuracy: 0.8861\n",
      "Epoch 26/30\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.2831 - accuracy: 0.8861\n",
      "Epoch 27/30\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.2964 - accuracy: 0.8861\n",
      "Epoch 28/30\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.2854 - accuracy: 0.8911\n",
      "Epoch 29/30\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.2693 - accuracy: 0.8861\n",
      "Epoch 30/30\n",
      "202/202 [==============================] - 0s 190us/sample - loss: 0.2668 - accuracy: 0.9010\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.2554 - accuracy: 0.8515\n",
      "Train on 202 samples\n",
      "Epoch 1/30\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6695 - accuracy: 0.5941\n",
      "Epoch 2/30\n",
      "202/202 [==============================] - 0s 194us/sample - loss: 0.6198 - accuracy: 0.7970\n",
      "Epoch 3/30\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.5613 - accuracy: 0.8465\n",
      "Epoch 4/30\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.5003 - accuracy: 0.8366\n",
      "Epoch 5/30\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.4293 - accuracy: 0.8564\n",
      "Epoch 6/30\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.3987 - accuracy: 0.8614\n",
      "Epoch 7/30\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.3675 - accuracy: 0.8663\n",
      "Epoch 8/30\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.3553 - accuracy: 0.8663\n",
      "Epoch 9/30\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.3604 - accuracy: 0.8614\n",
      "Epoch 10/30\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.3359 - accuracy: 0.8663\n",
      "Epoch 11/30\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.3309 - accuracy: 0.8861\n",
      "Epoch 12/30\n",
      "202/202 [==============================] - 0s 203us/sample - loss: 0.3257 - accuracy: 0.8614\n",
      "Epoch 13/30\n",
      "202/202 [==============================] - 0s 218us/sample - loss: 0.3177 - accuracy: 0.8762\n",
      "Epoch 14/30\n",
      "202/202 [==============================] - 0s 208us/sample - loss: 0.3148 - accuracy: 0.8762\n",
      "Epoch 15/30\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.3115 - accuracy: 0.8663\n",
      "Epoch 16/30\n",
      "202/202 [==============================] - 0s 194us/sample - loss: 0.3000 - accuracy: 0.8762\n",
      "Epoch 17/30\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3100 - accuracy: 0.8663\n",
      "Epoch 18/30\n",
      "202/202 [==============================] - 0s 218us/sample - loss: 0.3032 - accuracy: 0.8812\n",
      "Epoch 19/30\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.2908 - accuracy: 0.8861\n",
      "Epoch 20/30\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.2835 - accuracy: 0.8812\n",
      "Epoch 21/30\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.2778 - accuracy: 0.8861\n",
      "Epoch 22/30\n",
      "202/202 [==============================] - 0s 223us/sample - loss: 0.2760 - accuracy: 0.8861\n",
      "Epoch 23/30\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.2732 - accuracy: 0.8861\n",
      "Epoch 24/30\n",
      "202/202 [==============================] - 0s 215us/sample - loss: 0.2636 - accuracy: 0.8812\n",
      "Epoch 25/30\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.2628 - accuracy: 0.9010\n",
      "Epoch 26/30\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.2562 - accuracy: 0.8911\n",
      "Epoch 27/30\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.2590 - accuracy: 0.9010\n",
      "Epoch 28/30\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.2765 - accuracy: 0.8911\n",
      "Epoch 29/30\n",
      "202/202 [==============================] - 0s 218us/sample - loss: 0.2591 - accuracy: 0.8960\n",
      "Epoch 30/30\n",
      "202/202 [==============================] - 0s 227us/sample - loss: 0.2543 - accuracy: 0.8812\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3900 - accuracy: 0.8614\n",
      "Train on 202 samples\n",
      "Epoch 1/40\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6646 - accuracy: 0.7030\n",
      "Epoch 2/40\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.6160 - accuracy: 0.7376\n",
      "Epoch 3/40\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.5611 - accuracy: 0.7921\n",
      "Epoch 4/40\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.5064 - accuracy: 0.7822\n",
      "Epoch 5/40\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.4743 - accuracy: 0.7970\n",
      "Epoch 6/40\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.4501 - accuracy: 0.8069\n",
      "Epoch 7/40\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.4188 - accuracy: 0.8317\n",
      "Epoch 8/40\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.4201 - accuracy: 0.8020\n",
      "Epoch 9/40\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.4077 - accuracy: 0.8317\n",
      "Epoch 10/40\n",
      "202/202 [==============================] - 0s 181us/sample - loss: 0.4025 - accuracy: 0.8317\n",
      "Epoch 11/40\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.4079 - accuracy: 0.8168\n",
      "Epoch 12/40\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.4055 - accuracy: 0.8218\n",
      "Epoch 13/40\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.3946 - accuracy: 0.8218\n",
      "Epoch 14/40\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3894 - accuracy: 0.8366\n",
      "Epoch 15/40\n",
      "202/202 [==============================] - 0s 240us/sample - loss: 0.3950 - accuracy: 0.8317\n",
      "Epoch 16/40\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.3839 - accuracy: 0.8366\n",
      "Epoch 17/40\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.3950 - accuracy: 0.8119\n",
      "Epoch 18/40\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.3812 - accuracy: 0.8416\n",
      "Epoch 19/40\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.3846 - accuracy: 0.8267\n",
      "Epoch 20/40\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.3777 - accuracy: 0.8465\n",
      "Epoch 21/40\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.3733 - accuracy: 0.8465\n",
      "Epoch 22/40\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.3887 - accuracy: 0.8267\n",
      "Epoch 23/40\n",
      "202/202 [==============================] - 0s 194us/sample - loss: 0.3749 - accuracy: 0.8416\n",
      "Epoch 24/40\n",
      "202/202 [==============================] - 0s 218us/sample - loss: 0.3848 - accuracy: 0.8168\n",
      "Epoch 25/40\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.3756 - accuracy: 0.8317\n",
      "Epoch 26/40\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.3693 - accuracy: 0.8416\n",
      "Epoch 27/40\n",
      "202/202 [==============================] - 0s 223us/sample - loss: 0.3632 - accuracy: 0.8465\n",
      "Epoch 28/40\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3614 - accuracy: 0.8465\n",
      "Epoch 29/40\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.3663 - accuracy: 0.8465\n",
      "Epoch 30/40\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.3628 - accuracy: 0.8465\n",
      "Epoch 31/40\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.3596 - accuracy: 0.8614\n",
      "Epoch 32/40\n",
      "202/202 [==============================] - 0s 208us/sample - loss: 0.3585 - accuracy: 0.8564\n",
      "Epoch 33/40\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.3563 - accuracy: 0.8416\n",
      "Epoch 34/40\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.3499 - accuracy: 0.8614\n",
      "Epoch 35/40\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.3501 - accuracy: 0.8663\n",
      "Epoch 36/40\n",
      "202/202 [==============================] - 0s 329us/sample - loss: 0.3501 - accuracy: 0.8416\n",
      "Epoch 37/40\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.3472 - accuracy: 0.8614\n",
      "Epoch 38/40\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.3557 - accuracy: 0.8614\n",
      "Epoch 39/40\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.3589 - accuracy: 0.8663\n",
      "Epoch 40/40\n",
      "202/202 [==============================] - 0s 223us/sample - loss: 0.3446 - accuracy: 0.8614\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.1687 - accuracy: 0.8416\n",
      "Train on 202 samples\n",
      "Epoch 1/40\n",
      "202/202 [==============================] - 1s 5ms/sample - loss: 0.6912 - accuracy: 0.5000\n",
      "Epoch 2/40\n",
      "202/202 [==============================] - 0s 173us/sample - loss: 0.6578 - accuracy: 0.7030\n",
      "Epoch 3/40\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.6234 - accuracy: 0.7723\n",
      "Epoch 4/40\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.5755 - accuracy: 0.7871\n",
      "Epoch 5/40\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.5233 - accuracy: 0.7871\n",
      "Epoch 6/40\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.4778 - accuracy: 0.7970\n",
      "Epoch 7/40\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.4422 - accuracy: 0.8366\n",
      "Epoch 8/40\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4293 - accuracy: 0.7921\n",
      "Epoch 9/40\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.3910 - accuracy: 0.8168\n",
      "Epoch 10/40\n",
      "202/202 [==============================] - 0s 194us/sample - loss: 0.3767 - accuracy: 0.8218\n",
      "Epoch 11/40\n",
      "202/202 [==============================] - 0s 190us/sample - loss: 0.3659 - accuracy: 0.8168\n",
      "Epoch 12/40\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.3549 - accuracy: 0.8366\n",
      "Epoch 13/40\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.3547 - accuracy: 0.8317\n",
      "Epoch 14/40\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.3488 - accuracy: 0.8515\n",
      "Epoch 15/40\n",
      "202/202 [==============================] - 0s 406us/sample - loss: 0.3460 - accuracy: 0.8317\n",
      "Epoch 16/40\n",
      "202/202 [==============================] - 0s 352us/sample - loss: 0.3335 - accuracy: 0.8713\n",
      "Epoch 17/40\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.3343 - accuracy: 0.8465\n",
      "Epoch 18/40\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.3249 - accuracy: 0.8564\n",
      "Epoch 19/40\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3161 - accuracy: 0.8614\n",
      "Epoch 20/40\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.3152 - accuracy: 0.8614\n",
      "Epoch 21/40\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.3132 - accuracy: 0.8614\n",
      "Epoch 22/40\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.3030 - accuracy: 0.8713\n",
      "Epoch 23/40\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.3059 - accuracy: 0.8762\n",
      "Epoch 24/40\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.3089 - accuracy: 0.8564\n",
      "Epoch 25/40\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.2933 - accuracy: 0.8812\n",
      "Epoch 26/40\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.2919 - accuracy: 0.8911\n",
      "Epoch 27/40\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.2867 - accuracy: 0.8812\n",
      "Epoch 28/40\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.3000 - accuracy: 0.8762\n",
      "Epoch 29/40\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.2863 - accuracy: 0.8713\n",
      "Epoch 30/40\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.2737 - accuracy: 0.8960\n",
      "Epoch 31/40\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.2707 - accuracy: 0.8960\n",
      "Epoch 32/40\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.2702 - accuracy: 0.8960\n",
      "Epoch 33/40\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.2760 - accuracy: 0.8861\n",
      "Epoch 34/40\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.3062 - accuracy: 0.8762\n",
      "Epoch 35/40\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.2638 - accuracy: 0.9158\n",
      "Epoch 36/40\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.2814 - accuracy: 0.8861\n",
      "Epoch 37/40\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.2537 - accuracy: 0.9307\n",
      "Epoch 38/40\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.2506 - accuracy: 0.9158\n",
      "Epoch 39/40\n",
      "202/202 [==============================] - 0s 228us/sample - loss: 0.2703 - accuracy: 0.9109\n",
      "Epoch 40/40\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.2487 - accuracy: 0.9109\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.2979 - accuracy: 0.8317\n",
      "Train on 202 samples\n",
      "Epoch 1/40\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6791 - accuracy: 0.5743\n",
      "Epoch 2/40\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.6459 - accuracy: 0.5743\n",
      "Epoch 3/40\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.6047 - accuracy: 0.6782\n",
      "Epoch 4/40\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.5569 - accuracy: 0.7624\n",
      "Epoch 5/40\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.5035 - accuracy: 0.8119\n",
      "Epoch 6/40\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.4494 - accuracy: 0.8465\n",
      "Epoch 7/40\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.4113 - accuracy: 0.8614\n",
      "Epoch 8/40\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.4019 - accuracy: 0.8416\n",
      "Epoch 9/40\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.3826 - accuracy: 0.8812\n",
      "Epoch 10/40\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.3662 - accuracy: 0.8663\n",
      "Epoch 11/40\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.3728 - accuracy: 0.8564\n",
      "Epoch 12/40\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.3437 - accuracy: 0.8861\n",
      "Epoch 13/40\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.3495 - accuracy: 0.8515\n",
      "Epoch 14/40\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.3363 - accuracy: 0.8713\n",
      "Epoch 15/40\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.3344 - accuracy: 0.8762\n",
      "Epoch 16/40\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.3283 - accuracy: 0.8812\n",
      "Epoch 17/40\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.3192 - accuracy: 0.8713\n",
      "Epoch 18/40\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.3149 - accuracy: 0.8713\n",
      "Epoch 19/40\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.3195 - accuracy: 0.8812\n",
      "Epoch 20/40\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.3101 - accuracy: 0.8663\n",
      "Epoch 21/40\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.3043 - accuracy: 0.8663\n",
      "Epoch 22/40\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.3002 - accuracy: 0.8861\n",
      "Epoch 23/40\n",
      "202/202 [==============================] - 0s 218us/sample - loss: 0.2921 - accuracy: 0.8812\n",
      "Epoch 24/40\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.2873 - accuracy: 0.8861\n",
      "Epoch 25/40\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.2936 - accuracy: 0.8960\n",
      "Epoch 26/40\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.2828 - accuracy: 0.8861\n",
      "Epoch 27/40\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.2748 - accuracy: 0.8812\n",
      "Epoch 28/40\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.2665 - accuracy: 0.8960\n",
      "Epoch 29/40\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.2587 - accuracy: 0.8911\n",
      "Epoch 30/40\n",
      "202/202 [==============================] - 0s 229us/sample - loss: 0.2558 - accuracy: 0.9208\n",
      "Epoch 31/40\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.2569 - accuracy: 0.8960\n",
      "Epoch 32/40\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.2449 - accuracy: 0.9109\n",
      "Epoch 33/40\n",
      "202/202 [==============================] - 0s 190us/sample - loss: 0.2376 - accuracy: 0.9109\n",
      "Epoch 34/40\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.2360 - accuracy: 0.9109\n",
      "Epoch 35/40\n",
      "202/202 [==============================] - 0s 225us/sample - loss: 0.2325 - accuracy: 0.9158\n",
      "Epoch 36/40\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.2258 - accuracy: 0.9257\n",
      "Epoch 37/40\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.2301 - accuracy: 0.9257\n",
      "Epoch 38/40\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.2192 - accuracy: 0.9059\n",
      "Epoch 39/40\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.2203 - accuracy: 0.9307\n",
      "Epoch 40/40\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.2174 - accuracy: 0.9109\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3213 - accuracy: 0.8317\n",
      "Train on 202 samples\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6844 - accuracy: 0.5644\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.6573 - accuracy: 0.6139\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 225us/sample - loss: 0.6315 - accuracy: 0.7624\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.5988 - accuracy: 0.7574\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.5592 - accuracy: 0.7624\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.5225 - accuracy: 0.7673\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.4806 - accuracy: 0.7921\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.4477 - accuracy: 0.8020\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.4287 - accuracy: 0.8119\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.4265 - accuracy: 0.8069\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 225us/sample - loss: 0.4070 - accuracy: 0.8267\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 229us/sample - loss: 0.4042 - accuracy: 0.8267\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.3944 - accuracy: 0.8267\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.3913 - accuracy: 0.8416\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.3941 - accuracy: 0.8218\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 208us/sample - loss: 0.3828 - accuracy: 0.8317\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.3800 - accuracy: 0.8416\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3810 - accuracy: 0.8267\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.3748 - accuracy: 0.8465\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.3713 - accuracy: 0.8465\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.3681 - accuracy: 0.8465\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.3627 - accuracy: 0.8564\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.3610 - accuracy: 0.8614\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.3600 - accuracy: 0.8515\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.3669 - accuracy: 0.8366\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.3578 - accuracy: 0.8614\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.3584 - accuracy: 0.8564\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.3498 - accuracy: 0.8465\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.3536 - accuracy: 0.8416\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 229us/sample - loss: 0.3581 - accuracy: 0.8614\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 229us/sample - loss: 0.3696 - accuracy: 0.8218\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.3473 - accuracy: 0.8515\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 203us/sample - loss: 0.3410 - accuracy: 0.8416\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 225us/sample - loss: 0.3443 - accuracy: 0.8515\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.3357 - accuracy: 0.8713\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3339 - accuracy: 0.8762\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 189us/sample - loss: 0.3302 - accuracy: 0.8762\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.3331 - accuracy: 0.8564\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3451 - accuracy: 0.8713\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.3263 - accuracy: 0.8861\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.3201 - accuracy: 0.8812\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.3231 - accuracy: 0.8960\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.3237 - accuracy: 0.8614\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.3235 - accuracy: 0.8812\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.3230 - accuracy: 0.8762\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.3133 - accuracy: 0.8861\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.3177 - accuracy: 0.8762\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 237us/sample - loss: 0.3074 - accuracy: 0.8911\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 233us/sample - loss: 0.3031 - accuracy: 0.8960\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.3025 - accuracy: 0.9010\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.1817 - accuracy: 0.8317\n",
      "Train on 202 samples\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 1s 4ms/sample - loss: 0.6758 - accuracy: 0.4851\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.6314 - accuracy: 0.5446\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 233us/sample - loss: 0.5907 - accuracy: 0.7030\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 226us/sample - loss: 0.5395 - accuracy: 0.8069\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.4817 - accuracy: 0.8168\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 231us/sample - loss: 0.4202 - accuracy: 0.8317\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.3834 - accuracy: 0.8317\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 233us/sample - loss: 0.3642 - accuracy: 0.8416\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.3542 - accuracy: 0.8465\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - ETA: 0s - loss: 0.2059 - accuracy: 0.90 - 0s 246us/sample - loss: 0.3419 - accuracy: 0.8515\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.3418 - accuracy: 0.8713\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 231us/sample - loss: 0.3443 - accuracy: 0.8416\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.3293 - accuracy: 0.8762\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 240us/sample - loss: 0.3229 - accuracy: 0.8713\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.3211 - accuracy: 0.8614\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.3207 - accuracy: 0.8564\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.3152 - accuracy: 0.8911\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.3203 - accuracy: 0.8564\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.3069 - accuracy: 0.8911\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.3051 - accuracy: 0.8812\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.3002 - accuracy: 0.8663\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 234us/sample - loss: 0.2928 - accuracy: 0.8960\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 242us/sample - loss: 0.2980 - accuracy: 0.9010\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 240us/sample - loss: 0.2848 - accuracy: 0.8960\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.2844 - accuracy: 0.8713\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.2764 - accuracy: 0.9010\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.2739 - accuracy: 0.8960\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2827 - accuracy: 0.8812\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.2703 - accuracy: 0.9010\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.2773 - accuracy: 0.8663\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.2635 - accuracy: 0.9158\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.2517 - accuracy: 0.9158\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.2513 - accuracy: 0.9158\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.2577 - accuracy: 0.8960\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2461 - accuracy: 0.9158\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 591us/sample - loss: 0.2409 - accuracy: 0.8911\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.2530 - accuracy: 0.9059\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 223us/sample - loss: 0.2291 - accuracy: 0.9208\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.2231 - accuracy: 0.9257\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.2230 - accuracy: 0.9307\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 237us/sample - loss: 0.2173 - accuracy: 0.9208\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.2182 - accuracy: 0.9356\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 234us/sample - loss: 0.2253 - accuracy: 0.9010\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.2099 - accuracy: 0.9257\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.2010 - accuracy: 0.9356\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 225us/sample - loss: 0.2114 - accuracy: 0.9406\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.2020 - accuracy: 0.9257\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.1945 - accuracy: 0.9307\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.1917 - accuracy: 0.9307\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.1841 - accuracy: 0.9307\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.2613 - accuracy: 0.8515\n",
      "Train on 202 samples\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6693 - accuracy: 0.6535\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.6218 - accuracy: 0.7871\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.5712 - accuracy: 0.7921\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.5198 - accuracy: 0.8069\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.4657 - accuracy: 0.8218\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.4255 - accuracy: 0.8366\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.3911 - accuracy: 0.8465\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.3700 - accuracy: 0.8564\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.3530 - accuracy: 0.8713\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.3462 - accuracy: 0.8812\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.3402 - accuracy: 0.8713\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 215us/sample - loss: 0.3348 - accuracy: 0.8713\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.3507 - accuracy: 0.8713\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.3463 - accuracy: 0.8762\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.3315 - accuracy: 0.8762\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 189us/sample - loss: 0.3077 - accuracy: 0.8812\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.3072 - accuracy: 0.8861\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.3036 - accuracy: 0.8812\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.3020 - accuracy: 0.8762\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 178us/sample - loss: 0.2964 - accuracy: 0.8960\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.2890 - accuracy: 0.9010\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.2831 - accuracy: 0.9059\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.2852 - accuracy: 0.8960\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.2763 - accuracy: 0.8812\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.2753 - accuracy: 0.8911\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.2686 - accuracy: 0.9109\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.2607 - accuracy: 0.9010\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.2647 - accuracy: 0.9109\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.2908 - accuracy: 0.8564\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.2508 - accuracy: 0.9109\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.2483 - accuracy: 0.9059\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 237us/sample - loss: 0.2460 - accuracy: 0.9010\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.2400 - accuracy: 0.9257\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.2361 - accuracy: 0.9158\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.2338 - accuracy: 0.9010\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.2322 - accuracy: 0.9059\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 229us/sample - loss: 0.2329 - accuracy: 0.9010\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.2279 - accuracy: 0.8960\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 215us/sample - loss: 0.2284 - accuracy: 0.9010\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.2213 - accuracy: 0.9010\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 229us/sample - loss: 0.2104 - accuracy: 0.9257\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.2150 - accuracy: 0.9307\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.2122 - accuracy: 0.9010\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.2027 - accuracy: 0.9257\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.2015 - accuracy: 0.9257\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.2204 - accuracy: 0.8960\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.2315 - accuracy: 0.9010\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.1921 - accuracy: 0.9208\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 208us/sample - loss: 0.1918 - accuracy: 0.9208\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.1944 - accuracy: 0.9307\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3722 - accuracy: 0.8218\n",
      "Train on 303 samples\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 0.6420 - accuracy: 0.5677\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 0s 244us/sample - loss: 0.5819 - accuracy: 0.7327\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 0s 271us/sample - loss: 0.5173 - accuracy: 0.8020\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 0s 223us/sample - loss: 0.4572 - accuracy: 0.8185\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 0s 205us/sample - loss: 0.4113 - accuracy: 0.8449\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 0s 212us/sample - loss: 0.3953 - accuracy: 0.8449\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 0s 222us/sample - loss: 0.3826 - accuracy: 0.8515\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 0s 240us/sample - loss: 0.3642 - accuracy: 0.8482\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 0s 234us/sample - loss: 0.3528 - accuracy: 0.8647\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 0s 214us/sample - loss: 0.3558 - accuracy: 0.8548\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 0s 222us/sample - loss: 0.3498 - accuracy: 0.8449\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 0s 252us/sample - loss: 0.3544 - accuracy: 0.8548\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 0s 226us/sample - loss: 0.3395 - accuracy: 0.8680\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 0s 221us/sample - loss: 0.3327 - accuracy: 0.8548\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 0s 207us/sample - loss: 0.3321 - accuracy: 0.8647\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 0s 214us/sample - loss: 0.3285 - accuracy: 0.8746\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 0s 206us/sample - loss: 0.3204 - accuracy: 0.8680\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 0s 202us/sample - loss: 0.3211 - accuracy: 0.8779\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 0s 217us/sample - loss: 0.3169 - accuracy: 0.8680\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 0s 256us/sample - loss: 0.3115 - accuracy: 0.8746\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 0s 217us/sample - loss: 0.3068 - accuracy: 0.8779\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 0s 231us/sample - loss: 0.3204 - accuracy: 0.8647\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 0s 215us/sample - loss: 0.3020 - accuracy: 0.8845\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 0s 225us/sample - loss: 0.2941 - accuracy: 0.8845\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 0s 235us/sample - loss: 0.2959 - accuracy: 0.8845\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 0s 236us/sample - loss: 0.2939 - accuracy: 0.8878\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 0s 230us/sample - loss: 0.2874 - accuracy: 0.8878\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 0s 245us/sample - loss: 0.2875 - accuracy: 0.8944\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 0s 235us/sample - loss: 0.2810 - accuracy: 0.8845\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 0s 233us/sample - loss: 0.2805 - accuracy: 0.8812\n",
      "Best: 0.8613861203193665 using {'batch_size': 10, 'epochs': 30}\n",
      "Means: 0.8349834879239401, Stdev: 0.012348700566578033 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.8613861203193665, Stdev: 0.008084122154383987 with: {'batch_size': 10, 'epochs': 30}\n",
      "Means: 0.8349834879239401, Stdev: 0.004667370101995413 with: {'batch_size': 10, 'epochs': 40}\n",
      "Means: 0.8349834879239401, Stdev: 0.012348700566578033 with: {'batch_size': 10, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "# Now with a couple more hidden layers in the next iteration.\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 132\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=True)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10],\n",
    "              'epochs': [20, 30, 40, 50]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_2, y_2)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With two additional layers it actually works best with 30 epochs. I bet we could continue this and and get a bit better with more layers,\n",
    "# but I'll stop here for the sake of time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
